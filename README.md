# Clusterization

**О проекте:**

Это практическое задание по курсу "Машинное обучение" ФКН ВШЭ, посвящённое обучению без учителя. Здесь разобрано, как алгоритмы кластеризации и тематического моделирования работают на реальных географических и текстовых данных.

**Что внутри:**

* Кластеризация автобусных остановок Москвы с помощью алгоритмов: KMeans, DBSCAN, и спектральной кластеризации

* Тематическое моделирование текстов (на основе данных из новостных статей BBC за 2004-2005 годы) с помощью алгоритмов: KMeans, DBSCAN, спектральной кластеризации и использовали LDA (Latent Dirichlet Allocation) для выделения скрытых тем в корпусе.

* Semi-supervised подходы: немного поработали с задачами, где есть и размеченные, и неразмеченные данные

**Что интересного:**
* Реализация спектральной кластеризации с нуля

* Сравнение разных подходов и визуализация результатов

* Тематическое моделирование, позволяющее "вскрыть" смыслы в текстах

**Стек:**

* Python (numpy, pandas, matplotlib, scikit-learn)

* NLTK / Gensim / LDA

**Выводы:**

**По кластеризации остановок:**

* KMeans - равномерно распределяет кластеры, хорошо делит по плотности. Но не учитывает форму кластеров и связи между остановками — может "резать" логически связанные точки. Поэтому кластеры выглядят слишко красиво и одинакого.

* DBSCAN - очень сложно подобрать гиперпараметры, потому что в пределах москвы все остановки расположены примерно равномерно. Из-за этого этоот алгоритм видит только маленькие более плотные групки остановок, а все овтальное считает выбросом.

* Spectral Clustering - учитывает структуру связей между остановками (в отличие от KMeans), создаёт логичные и компактные группы (не такие ровные как в KMeans). Но что-то очень медленный, хотя ради результата можно и подождать.

По итогу лучше всего подходит Spectral Clustering, тк он учитывает не только координаты, но и маршруты и формирет более осмысленные и связные кластеры.

**По тематическому моделированию текстов:**

* KMeans дал в целом сбалансированные и чёткие кластеры, без сильного перекрытия. Почти все точки попали в кластеры. Структура как всегда похожа на "островки".

* DBSCAN — почти весь граф серый: большинство точек попали в шум (label = -1). Те точки, что попали в кластеры — действительно локально плотные. В целом ситуация такая-же, как и с картами.

* Spectral Clustering показал похожее поведение на KMeans, но шума вроде поменьше и кластеры покрупнее. Это объясняется тем, что Spectral лучше справляется с нелинейной формой кластеров.

Темы, полученные с помощью LDA, действительно оказались более узкими и смысловыми, чем при кластеризации KMeans. 

**По Semi-supervised подходам:**

* После перехода к обучению с 5% разметки результаты, конечно, просели, но не катастрофически. TF-IDF + логрег потерял свои лидерские позиции, потому что теперь ему пришлось выжимать максимум из пары десятков размеченных примеров.

* KMeans + логрег наоборот значительно улучшил свои предсказания (на 12%). Скорее всего, это связано с тем, что алгоритм достаточно устойчив: он просто "запоминает", какие тексты ближе к каким кластерам. Поэтому он особо не прочуствовал уменьшение трейна, но зато стал лучше работать за счет подбора гиперпараметров.

* LDA + логрег теперь лидер (93.4%), но результат ухудшился по сравнению с обучением на полной разметке.

В целом: когда меток мало — простые, устойчивые признаки (темы, расстояния) работают лучше, чем TF-IDF.
